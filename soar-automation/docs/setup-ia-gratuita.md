# ü§ñ Alternativas de IA Gratuitas para SOAR

## Por que usar alternativas gratuitas?

O workflow original usa OpenAI (pago). Estas alternativas s√£o:
- ‚úÖ **Gratuitas** (ou locais)
- ‚úÖ **R√°pidas** (Groq √© extremamente r√°pido)
- ‚úÖ **Sem limites de custo** (Ollama √© local)

---

## üöÄ Op√ß√£o 1: Groq (RECOMENDADO)

**Caracter√≠sticas:**
- ‚úÖ **Gratuito** (6.000 requests/dia, 30 req/min)
- ‚úÖ **Extremamente r√°pido** (at√© 10x mais r√°pido que OpenAI)
- ‚úÖ **API compat√≠vel com OpenAI**
- ‚úÖ **V√°rios modelos:** Llama 3, Mixtral, Gemma

### Setup Groq

#### 1. Obter API Key

1. Acesse: https://console.groq.com/
2. Crie conta gratuita
3. V√° em **API Keys**
4. Clique em **Create API Key**
5. Copie a chave (formato: `gsk_...`)

#### 2. Configurar no n8n

**Op√ß√£o A: HTTP Request Node (SIMPLES)**

No workflow, substitua o n√≥ "IA Analysis (OpenAI)" por **HTTP Request**:

```json
{
  "parameters": {
    "method": "POST",
    "url": "https://api.groq.com/openai/v1/chat/completions",
    "authentication": "genericCredentialType",
    "genericAuthType": "httpHeaderAuth",
    "sendHeaders": true,
    "headerParameters": {
      "parameters": [
        {
          "name": "Authorization",
          "value": "=Bearer {{ $credentials.groqApiKey }}"
        },
        {
          "name": "Content-Type",
          "value": "application/json"
        }
      ]
    },
    "sendBody": true,
    "bodyParameters": {
      "parameters": [
        {
          "name": "body",
          "value": "={{ JSON.stringify({\n  model: 'llama-3.1-70b-versatile',\n  messages: [\n    {\n      role: 'system',\n      content: $('Load IA Prompt').item.json.system_prompt\n    },\n    {\n      role: 'user',\n      content: $('Load IA Prompt').item.json.user_prompt\n    }\n  ],\n  temperature: 0.3,\n  max_tokens: 1000\n}) }}"
        }
      ]
    },
    "options": {}
  },
  "name": "IA Analysis (Groq)",
  "type": "n8n-nodes-base.httpRequest"
}
```

**Credencial HTTP Header Auth:**
- Nome: `Groq API`
- Header Name: `Authorization`
- Header Value: `Bearer gsk_sua_api_key_aqui`

#### 3. Modelos Dispon√≠veis (Groq)

| Modelo | Descri√ß√£o | Velocidade | Qualidade |
|--------|-----------|------------|-----------|
| `llama-3.1-70b-versatile` | **RECOMENDADO** | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| `llama-3.1-8b-instant` | Mais r√°pido | ‚ö°‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê |
| `mixtral-8x7b-32768` | Contexto longo | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê |
| `gemma2-9b-it` | Google Gemma | ‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê |

**Recomenda√ß√£o:** Use `llama-3.1-70b-versatile` (melhor custo-benef√≠cio).

#### 4. Limites Gratuitos

- **Requests/dia:** 14.400 (mais que suficiente)
- **Requests/minuto:** 30
- **Tokens/minuto:** 7.000

---

## üíª Op√ß√£o 2: Ollama (Local - SEM CUSTOS)

**Caracter√≠sticas:**
- ‚úÖ **100% Gratuito**
- ‚úÖ **Sem limites**
- ‚úÖ **Privacidade total** (roda local)
- ‚úÖ **Offline** (n√£o precisa internet)
- ‚ö†Ô∏è Requer GPU ou CPU potente

### Setup Ollama

#### 1. Instalar Ollama

**Linux:**
```bash
curl -fsSL https://ollama.com/install.sh | sh
```

**Windows:**
- Baixe: https://ollama.com/download/windows
- Execute o instalador

**macOS:**
```bash
brew install ollama
```

#### 2. Baixar Modelo

```bash
# Modelo recomendado (3GB)
ollama pull llama3.2:3b

# Ou modelo maior (4.7GB)
ollama pull llama3.1:8b

# Ou Mixtral (26GB - requer GPU)
ollama pull mixtral:8x7b
```

#### 3. Iniciar Servidor

```bash
# Linux/macOS
ollama serve

# Windows (j√° inicia automaticamente)
```

Servidor fica em: `http://localhost:11434`

#### 4. Configurar no n8n

**HTTP Request Node:**

```json
{
  "parameters": {
    "method": "POST",
    "url": "http://localhost:11434/api/generate",
    "sendBody": true,
    "bodyParameters": {
      "parameters": [
        {
          "name": "body",
          "value": "={{ JSON.stringify({\n  model: 'llama3.2:3b',\n  prompt: $('Load IA Prompt').item.json.system_prompt + '\\n\\n' + $('Load IA Prompt').item.json.user_prompt,\n  stream: false,\n  format: 'json',\n  options: {\n    temperature: 0.3,\n    num_predict: 1000\n  }\n}) }}"
        }
      ]
    },
    "options": {}
  },
  "name": "IA Analysis (Ollama)",
  "type": "n8n-nodes-base.httpRequest"
}
```

**Sem credenciais necess√°rias!** (roda local)

#### 5. Modelos Recomendados (Ollama)

| Modelo | Tamanho | RAM M√≠nimo | GPU | Qualidade |
|--------|---------|------------|-----|-----------|
| `llama3.2:3b` | 2GB | 8GB | Opcional | ‚≠ê‚≠ê‚≠ê‚≠ê |
| `llama3.1:8b` | 4.7GB | 8GB | Recomendado | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| `phi3:medium` | 7.9GB | 16GB | Recomendado | ‚≠ê‚≠ê‚≠ê‚≠ê |
| `mixtral:8x7b` | 26GB | 32GB | Necess√°rio | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |

**Para hardware humilde:** `llama3.2:3b`

---

## üåê Op√ß√£o 3: Google Gemini (Gratuito)

**Caracter√≠sticas:**
- ‚úÖ **Gratuito** (60 req/min)
- ‚úÖ **Qualidade alta**
- ‚úÖ **Multimodal** (aceita imagens)
- ‚ö†Ô∏è Requer conta Google

### Setup Gemini

#### 1. Obter API Key

1. Acesse: https://aistudio.google.com/app/apikey
2. Login com conta Google
3. Clique em **Get API Key**
4. Copie a chave

#### 2. Configurar no n8n

**HTTP Request Node:**

```json
{
  "parameters": {
    "method": "POST",
    "url": "=https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={{ $credentials.geminiApiKey }}",
    "sendBody": true,
    "bodyParameters": {
      "parameters": [
        {
          "name": "body",
          "value": "={{ JSON.stringify({\n  contents: [{\n    parts: [{\n      text: $('Load IA Prompt').item.json.system_prompt + '\\n\\n' + $('Load IA Prompt').item.json.user_prompt\n    }]\n  }],\n  generationConfig: {\n    temperature: 0.3,\n    maxOutputTokens: 1000\n  }\n}) }}"
        }
      ]
    },
    "options": {}
  },
  "name": "IA Analysis (Gemini)",
  "type": "n8n-nodes-base.httpRequest"
}
```

**Credencial (armazenada como vari√°vel):**
- Nome: `geminiApiKey`
- Valor: `sua_api_key_aqui`

#### 3. Modelos Dispon√≠veis

| Modelo | Gr√°tis? | Velocidade | Qualidade |
|--------|---------|------------|-----------|
| `gemini-1.5-flash` | ‚úÖ 60 req/min | ‚ö°‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê |
| `gemini-1.5-pro` | ‚úÖ 2 req/min | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |

**Recomenda√ß√£o:** `gemini-1.5-flash` (r√°pido e gratuito)

---

## üìä Compara√ß√£o

| IA | Custo | Velocidade | Setup | Offline | Qualidade | Limites |
|----|-------|------------|-------|---------|-----------|---------|
| **Groq** | üü¢ Gr√°tis | ‚ö°‚ö°‚ö°‚ö°‚ö° | ‚≠ê F√°cil | ‚ùå | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | 14.4k/dia |
| **Ollama** | üü¢ Gr√°tis | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê M√©dio | ‚úÖ | ‚≠ê‚≠ê‚≠ê‚≠ê | Ilimitado |
| **Gemini** | üü¢ Gr√°tis | ‚ö°‚ö°‚ö°‚ö° | ‚≠ê F√°cil | ‚ùå | ‚≠ê‚≠ê‚≠ê‚≠ê | 60/min |
| **OpenAI** | üî¥ Pago | ‚ö°‚ö°‚ö° | ‚≠ê F√°cil | ‚ùå | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Depende $ |

---

## üéØ Recomenda√ß√£o por Cen√°rio

### Hardware Humilde + Internet Boa
**‚Üí Use Groq** üèÜ
- Extremamente r√°pido
- Gratuito
- Sem instala√ß√£o local

### Hardware Humilde + Internet Inst√°vel
**‚Üí Use Ollama (llama3.2:3b)** üèÜ
- Funciona offline
- Sem custos
- 2GB de download

### Hardware Potente
**‚Üí Use Ollama (llama3.1:8b ou mixtral)** üèÜ
- Melhor qualidade
- Privacidade total
- Sem limites

### Necessita Multimodal (an√°lise de imagens)
**‚Üí Use Gemini** üèÜ
- Aceita imagens
- Gratuito
- Alta qualidade

---

## üõ†Ô∏è Como Trocar no Workflow

### Passo 1: Abra o workflow no n8n

### Passo 2: Delete o n√≥ "IA Analysis (OpenAI)"

### Passo 3: Adicione um n√≥ "HTTP Request"

### Passo 4: Configure conforme a IA escolhida (veja exemplos acima)

### Passo 5: Conecte:
```
Load IA Prompt ‚Üí IA Analysis (Groq/Ollama/Gemini) ‚Üí Parse IA Response
```

### Passo 6: Ajuste o n√≥ "Parse IA Response"

O parse precisa extrair a resposta do formato espec√≠fico de cada API:

**Para Groq/OpenAI:**
```javascript
const iaResponse = $input.first().json.choices[0].message.content;
```

**Para Ollama:**
```javascript
const iaResponse = $input.first().json.response;
```

**Para Gemini:**
```javascript
const iaResponse = $input.first().json.candidates[0].content.parts[0].text;
```

---

## üîß Troubleshooting

### Groq: Erro 429 (Rate Limit)
- Voc√™ atingiu o limite de 30 req/min
- Aguarde 1 minuto ou use modelo mais r√°pido

### Ollama: Connection refused
```bash
# Verifique se est√° rodando
curl http://localhost:11434/api/tags

# Se n√£o, inicie
ollama serve
```

### Gemini: Erro 400
- Verifique formato do JSON
- API Key est√° correta?
- Modelo existe? (use gemini-1.5-flash)

---

## üìö Links √öteis

- **Groq:** https://console.groq.com/
- **Ollama:** https://ollama.com/
- **Gemini:** https://aistudio.google.com/

---

**Recomenda√ß√£o final:** Comece com **Groq** (mais f√°cil). Se precisar de privacidade, migre para **Ollama**.
